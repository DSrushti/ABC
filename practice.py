# -*- coding: utf-8 -*-
"""Practice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KBezuemYiU_WlAwuDzrY6277ZUSslTdI
"""

import pandas as pd

data = pd.read_csv('data.csv')

data = data.drop('Start station',axis = 1)
data = data.drop('End station',axis = 1)
data = data.drop('Start date',axis = 1)
data = data.drop('End date',axis = 1)
data.shape

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(data['Bike number'])
data['Bike number'] = le.transform(data['Bike number']);

X = data.iloc[:,:-1].values
y = data.iloc[:,-1].values
print(X.shape)
print(y.shape)

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
X = ss.fit_transform(X)

from sklearn.model_selection import train_test_split
train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.25,random_state = 0);

train_Y.shape

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(train_X,train_Y);

pre = model.predict(test_X)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(test_Y,pre)
print(cm)

acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[1][1]+cm[0][1]+cm[1][0])
print(acc)

import seaborn as sbs
sbs.heatmap(cm);

dataf = pd.read_csv('diabetes.csv')

X = dataf.iloc[:,:-1]
Y = dataf.iloc[:,-1]

from sklearn.model_selection import train_test_split
T_X,t_x,T_Y,t_y  = train_test_split(X,Y,test_size = 0.25)

T_P = T_X[T_Y==1].mean()
T_N = T_X[T_Y==0].mean()
T_P_S = T_X[T_Y==1].std()
T_N_S = T_X[T_Y==0].std()

Sum = {"T_P":T_P,"T_P_S":T_P_S,"T_N":T_N,"T_N_S":T_N_S}

import numpy as np
def con(value,mean,std):
    var = std*std
    p = (1/(np.sqrt(2*np.pi*var)))*(np.exp((-(value-mean)*(value-mean))/(2*var)))
    return p;

con(1,2,3)

def predict(row,summary):
  pos_pro = len(summary["T_P"])/(len(summary["T_P"])+len(summary["T_N"]))
  //print(pos_pro)
  for i in range(0,len(row)):
    pos_pro = pos_pro * con(row[i],summary["T_P"][i],summary["T_P_S"][i])
  neg_pro = len(summary["T_N"])/(len(summary["T_P"])+len(summary["T_N"]))
  for i in range(0,len(row)):
    neg_pro = neg_pro * con(row[i],summary["T_N"][i],summary["T_N_S"][i])
  return [pos_pro,neg_pro]

prer = []
for row in t_x.values.tolist():
  prer.append(predict(row,Sum));

print(prer[0])

pred = []
for row in prer :
  if(row[0]>row[1]):
      pred.append(0)
  else:
      pred.append(1)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(t_y,pred)
print(cm)

import seaborn as sbs
sbs.heatmap(cm)
